{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.layers import Dense, Input, Embedding, Reshape, Dropout, LeakyReLU, Flatten\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as Backend\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "Backend.tensorflow_backend._get_available_gpus()\n",
    "import tensorflow as k\n",
    "config = k.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "592bf5457c22752514d40d5ea08d485fa2fc9b3d"
   },
   "outputs": [],
   "source": [
    "def load_Data(url):\n",
    "    client = MongoClient(url)\n",
    "    db = client['lounjee']\n",
    "    matches = db['matches']\n",
    "    users = db['users']\n",
    "    feedbacks = db['meetingFeedbackAnswers']\n",
    "    dialogs = db['dialogs']\n",
    "    \n",
    "    result = []\n",
    "    for item in users.find():\n",
    "        result.append(str(item['_id']))\n",
    "    df = pd.DataFrame(data=np.zeros((len(result),len(result))), index=result,dtype=np.int8, columns=result)\n",
    "    \n",
    "    def find_item(df,usera,userb,value=0):\n",
    "        df[userb][usera] = value\n",
    "        return df[userb][usera]\n",
    "        \n",
    "    for item in matches.find():\n",
    "        try:\n",
    "            if item['stateA']['type'] == 'accepted':\n",
    "                find_item(df,str(item['userA']),str(item['userB']),1)\n",
    "            elif item['stateA']['type'] == 'accepting':\n",
    "                find_item(df,str(item['userA']),str(item['userB']),1)\n",
    "            elif item['stateA']['type'] == 'postponed':\n",
    "                find_item(df,str(item['userA']),str(item['userB']),1)\n",
    "    #         elif item['stateA']['type'] == 'reporting':\n",
    "    #             find_item(df,str(item['userA']),str(item['userB']),-5)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    for item in users.find():\n",
    "        try:\n",
    "            if item['favorites']:\n",
    "                for f in item['favorites']:\n",
    "                    find_item(df,str(item['_id']),str(f['_id']),1)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    df = df[(df.T != 0).any()]\n",
    "    \n",
    "    result=[]\n",
    "    for i in df.index.values:\n",
    "        for idx,val in enumerate(df.loc[i]):\n",
    "            result.append({'usera':i,'userb':(df.loc[i].index)[idx],'rating':val})\n",
    "\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ae5dbb0e07588e5a38ab6760ca9ab2fa9b90a0c7"
   },
   "outputs": [],
   "source": [
    "def data_Engineering(ratings,data, sampling=1):\n",
    "    # Random under sampling\n",
    "    if sampling is 1:\n",
    "        count_class_0, count_class_1 = ratings.rating.value_counts()\n",
    "        df_class_0 = ratings[ratings['rating'] == 0]\n",
    "        df_class_1 = ratings[ratings['rating'] == 1]\n",
    "        df_class_0_under = df_class_0.sample(count_class_1)\n",
    "        ratings = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "    elif sampling is 2:\n",
    "        count_class_0, count_class_1 = ratings.rating.value_counts()\n",
    "        df_class_0 = ratings[ratings['rating'] == 0]\n",
    "        df_class_1 = ratings[ratings['rating'] == 1]\n",
    "        df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "        ratings = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "    \n",
    "    ## reset index\n",
    "    ratings.reset_index(inplace=True,drop=True)\n",
    "    ratings.head()\n",
    "    \n",
    "    ## One hot encoding\n",
    "    def dum(df,name):\n",
    "        dummies = df[name].str.get_dummies(sep=',').add_prefix(name+'_')\n",
    "        df.drop([name],axis=1,inplace=True)\n",
    "        dummies\n",
    "        df = df.join(dummies)\n",
    "        return df\n",
    "    arr = list(data)\n",
    "    for val in arr:\n",
    "        if val == 'uid':\n",
    "            continue\n",
    "        data = dum(data,val)\n",
    "    \n",
    "    result = pd.merge(ratings, data, left_on='usera',right_on='uid')\n",
    "    result.drop(['usera','uid'], axis=1, inplace=True)\n",
    "    result = pd.merge(result, data, left_on='userb',right_on='uid')\n",
    "    result.drop(['uid','userb'], axis=1, inplace=True)\n",
    "    \n",
    "    del data\n",
    "    del ratings\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "96e0477c5d129f38de090f3fc36e72243c22c303"
   },
   "outputs": [],
   "source": [
    "def train(data,length=743):\n",
    "    def EmbeddingNetV3(n1_features,n2_features,n_latent_factors_user = 5,n_latent_factors_item = 8,n_users=743):\n",
    "        model1_in = Input(shape=(n1_features,),name='userInput')\n",
    "        model1_out = Embedding(input_dim = n_users+1, output_dim = n_latent_factors_user)(model1_in)\n",
    "        model1_out = Flatten()(model1_out)\n",
    "        model1_out = Dropout(0.2)(model1_out)\n",
    "\n",
    "        model2_in = Input(shape=(n2_features,),name='itemInput')\n",
    "        model2_out = Embedding(input_dim = n_users+1, output_dim = n_latent_factors_item)(model2_in)\n",
    "        model2_out = Flatten()(model2_out)\n",
    "        model2_out = Dropout(0.2)(model2_out)\n",
    "\n",
    "        model = concatenate([model1_out, model2_out],axis=-1)\n",
    "        model = LeakyReLU(alpha=0.15)(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "        model = Dense(200)(model)\n",
    "        model = LeakyReLU(alpha=0.15)(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "        model = Dense(100)(model)\n",
    "        model = LeakyReLU(alpha=0.15)(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "        model = Dense(50)(model)\n",
    "        model = LeakyReLU(alpha=0.15)(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "        model = Dense(20)(model)\n",
    "        model = LeakyReLU(alpha=0.15)(model)\n",
    "\n",
    "        model = Dense(2, activation='softmax')(model)\n",
    "        adam = Adam(lr=0.005)\n",
    "        model = Model([model1_in, model2_in], model)\n",
    "        model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "#     userb = pd.factorize(data.userb)[0]\n",
    "    usera = data.iloc[:,1:525]\n",
    "    userb = data.iloc[:,525:]\n",
    "    n = length\n",
    "    X = [usera,userb]\n",
    "    y = data.rating\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = np_utils.to_categorical(encoder.transform(y), 2)\n",
    "    \n",
    "    callback = [EarlyStopping(patience=2,monitor='val_acc')]\n",
    "    \n",
    "    model = EmbeddingNetV3(n1_features=usera.shape[1],n2_features=userb.shape[1],n_users=n)\n",
    "    history = model.fit(X,y,batch_size=1000,epochs=100,verbose=1,callbacks = callback)\n",
    "    def saveModel(model):\n",
    "        model_json = model.to_json()\n",
    "        open('lounjee_rs_architecture.json', 'w').write(model_json)\n",
    "        model.save_weights('lounjee_rs_weights.h5', overwrite=True)\n",
    "    saveModel(model)\n",
    "    return (model,history,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "69bb3f3966b3ce23a0669cc7e14ad74d4bf086a7"
   },
   "outputs": [],
   "source": [
    "ratings = load_Data(\"mongodb://178.128.161.146:27017/\")\n",
    "data = pd.read_csv('./data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "dccbaabf1515e42cca6676de836b7265cf1716c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/100\n",
      "544172/544172 [==============================] - 22s 41us/step - loss: 0.2944 - acc: 0.8728\n",
      "Epoch 2/100\n",
      "544172/544172 [==============================] - 23s 42us/step - loss: 0.1939 - acc: 0.9265\n",
      "Epoch 3/100\n",
      "544172/544172 [==============================] - 23s 42us/step - loss: 0.1665 - acc: 0.9391\n",
      "Epoch 4/100\n",
      "544172/544172 [==============================] - 23s 42us/step - loss: 0.1504 - acc: 0.9463\n",
      "Epoch 5/100\n",
      "544172/544172 [==============================] - 23s 42us/step - loss: 0.1397 - acc: 0.9509\n",
      "Epoch 6/100\n",
      "544172/544172 [==============================] - 23s 43us/step - loss: 0.1329 - acc: 0.9535\n",
      "Epoch 7/100\n",
      "544172/544172 [==============================] - 22s 41us/step - loss: 0.1268 - acc: 0.9559\n",
      "Epoch 8/100\n",
      "544172/544172 [==============================] - 23s 42us/step - loss: 0.1228 - acc: 0.9576\n",
      "Epoch 9/100\n",
      "544172/544172 [==============================] - 23s 42us/step - loss: 0.1187 - acc: 0.9595\n",
      "Epoch 10/100\n",
      "544172/544172 [==============================] - 24s 43us/step - loss: 0.1157 - acc: 0.9606\n",
      "Epoch 11/100\n",
      "544172/544172 [==============================] - 24s 44us/step - loss: 0.1127 - acc: 0.9619\n",
      "Epoch 12/100\n",
      "544172/544172 [==============================] - 23s 43us/step - loss: 0.1100 - acc: 0.9626\n",
      "Epoch 13/100\n",
      "544172/544172 [==============================] - 23s 42us/step - loss: 0.1082 - acc: 0.9635\n",
      "Epoch 14/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.1065 - acc: 0.9640\n",
      "Epoch 15/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.1042 - acc: 0.9650\n",
      "Epoch 16/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.1019 - acc: 0.9659\n",
      "Epoch 17/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.1015 - acc: 0.9659\n",
      "Epoch 18/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0993 - acc: 0.9670\n",
      "Epoch 19/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0987 - acc: 0.9671\n",
      "Epoch 20/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0976 - acc: 0.9674\n",
      "Epoch 21/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0964 - acc: 0.9679\n",
      "Epoch 22/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0955 - acc: 0.9684\n",
      "Epoch 23/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0937 - acc: 0.9691\n",
      "Epoch 24/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0929 - acc: 0.9689\n",
      "Epoch 25/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0919 - acc: 0.9695\n",
      "Epoch 26/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0919 - acc: 0.9696\n",
      "Epoch 27/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0896 - acc: 0.9704\n",
      "Epoch 28/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0894 - acc: 0.9703\n",
      "Epoch 29/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0891 - acc: 0.9705\n",
      "Epoch 30/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0883 - acc: 0.9709\n",
      "Epoch 31/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0879 - acc: 0.9707\n",
      "Epoch 32/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0871 - acc: 0.9710\n",
      "Epoch 33/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0870 - acc: 0.9713\n",
      "Epoch 34/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0858 - acc: 0.9718\n",
      "Epoch 35/100\n",
      "544172/544172 [==============================] - 20s 38us/step - loss: 0.0859 - acc: 0.9718\n",
      "Epoch 36/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0845 - acc: 0.9722\n",
      "Epoch 37/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0850 - acc: 0.9723\n",
      "Epoch 38/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0828 - acc: 0.9726\n",
      "Epoch 39/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0834 - acc: 0.9724\n",
      "Epoch 40/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0822 - acc: 0.9731\n",
      "Epoch 41/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0832 - acc: 0.9729\n",
      "Epoch 42/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0820 - acc: 0.9732\n",
      "Epoch 43/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0816 - acc: 0.9733\n",
      "Epoch 44/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0815 - acc: 0.9733\n",
      "Epoch 45/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0811 - acc: 0.9734\n",
      "Epoch 46/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0805 - acc: 0.9737\n",
      "Epoch 47/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0800 - acc: 0.9738\n",
      "Epoch 48/100\n",
      "544172/544172 [==============================] - 20s 38us/step - loss: 0.0798 - acc: 0.9738\n",
      "Epoch 49/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0793 - acc: 0.9740\n",
      "Epoch 50/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0788 - acc: 0.9742\n",
      "Epoch 51/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0786 - acc: 0.9741\n",
      "Epoch 52/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0794 - acc: 0.9739\n",
      "Epoch 53/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0780 - acc: 0.9744\n",
      "Epoch 54/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0777 - acc: 0.9746\n",
      "Epoch 55/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0773 - acc: 0.9748\n",
      "Epoch 56/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0773 - acc: 0.9747\n",
      "Epoch 57/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0770 - acc: 0.9749\n",
      "Epoch 58/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0760 - acc: 0.9751\n",
      "Epoch 59/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0768 - acc: 0.9750\n",
      "Epoch 60/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0759 - acc: 0.9752\n",
      "Epoch 61/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0762 - acc: 0.9752\n",
      "Epoch 62/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0759 - acc: 0.9752\n",
      "Epoch 63/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0750 - acc: 0.9755\n",
      "Epoch 64/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0759 - acc: 0.9755\n",
      "Epoch 65/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0758 - acc: 0.9753\n",
      "Epoch 66/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0747 - acc: 0.9756\n",
      "Epoch 67/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0747 - acc: 0.9757\n",
      "Epoch 68/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0740 - acc: 0.9758\n",
      "Epoch 69/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0747 - acc: 0.9756\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0745 - acc: 0.9756\n",
      "Epoch 71/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0733 - acc: 0.9760\n",
      "Epoch 72/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0724 - acc: 0.9765\n",
      "Epoch 73/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0727 - acc: 0.9760\n",
      "Epoch 74/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0732 - acc: 0.9764\n",
      "Epoch 75/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0725 - acc: 0.9764\n",
      "Epoch 76/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0723 - acc: 0.9763\n",
      "Epoch 77/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0723 - acc: 0.9763\n",
      "Epoch 78/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0716 - acc: 0.9764\n",
      "Epoch 79/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0719 - acc: 0.9766\n",
      "Epoch 80/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0719 - acc: 0.9765\n",
      "Epoch 81/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0716 - acc: 0.9766\n",
      "Epoch 82/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0719 - acc: 0.9767\n",
      "Epoch 83/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0715 - acc: 0.9766\n",
      "Epoch 84/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0706 - acc: 0.9769\n",
      "Epoch 85/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0713 - acc: 0.9767\n",
      "Epoch 86/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0704 - acc: 0.9769\n",
      "Epoch 87/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0710 - acc: 0.9768\n",
      "Epoch 88/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0711 - acc: 0.9768\n",
      "Epoch 89/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0704 - acc: 0.9770\n",
      "Epoch 90/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0708 - acc: 0.9769\n",
      "Epoch 91/100\n",
      "544172/544172 [==============================] - 22s 40us/step - loss: 0.0706 - acc: 0.9770\n",
      "Epoch 92/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0700 - acc: 0.9773\n",
      "Epoch 93/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0700 - acc: 0.9773\n",
      "Epoch 94/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0694 - acc: 0.9774\n",
      "Epoch 95/100\n",
      "544172/544172 [==============================] - 21s 38us/step - loss: 0.0696 - acc: 0.9772\n",
      "Epoch 96/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0697 - acc: 0.9772\n",
      "Epoch 97/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0688 - acc: 0.9776\n",
      "Epoch 98/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0685 - acc: 0.9779\n",
      "Epoch 99/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0699 - acc: 0.9774\n",
      "Epoch 100/100\n",
      "544172/544172 [==============================] - 21s 39us/step - loss: 0.0694 - acc: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.training.Model at 0x7f92104d1c88>,\n",
       " <keras.callbacks.History at 0x7f92104e9748>,\n",
       " [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 0, ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])],\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = data_Engineering(ratings,data,sampling=2)\n",
    "train(result)\n",
    "# (model,history,X,y) = train(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4026dd972fb0116d805733f78990a60dec399ecd"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "def loadModel():\n",
    "    model_architecture = 'lounjee_rs_architecture.json'\n",
    "    model_weights = 'lounjee_rs_weights.h5'\n",
    "    model = model_from_json(open(model_architecture).read())\n",
    "    model.load_weights(model_weights)\n",
    "    return model\n",
    "model = loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "f05546fe6e89974b7c788f91dd173183bdf8fffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544172/544172 [==============================] - 22s 41us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.050272181908310974, 0.9827462640488669]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usera = result.iloc[:,1:525]\n",
    "userb = result.iloc[:,525:]\n",
    "n = 743\n",
    "X = [usera,userb]\n",
    "y = result.rating\n",
    "    \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = np_utils.to_categorical(encoder.transform(y), 2)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.evaluate(X,y,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72c515005e2ccf8326cca4d7fa74bc4e48bad4b6"
   },
   "outputs": [],
   "source": [
    "# pred_y = model.predict(X)\n",
    "# pred_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
